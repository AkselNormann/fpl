{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Packages\" data-toc-modified-id=\"Import-Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Packages</a></span></li><li><span><a href=\"#Read-Data\" data-toc-modified-id=\"Read-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Read Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Player-Performance\" data-toc-modified-id=\"Player-Performance-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Player Performance</a></span></li><li><span><a href=\"#Team\" data-toc-modified-id=\"Team-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Team</a></span></li><li><span><a href=\"#Fixtures\" data-toc-modified-id=\"Fixtures-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fixtures</a></span></li><li><span><a href=\"#Players\" data-toc-modified-id=\"Players-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Players</a></span></li></ul></li><li><span><a href=\"#Feature-Development\" data-toc-modified-id=\"Feature-Development-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Feature Development</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-DataFrame\" data-toc-modified-id=\"Setup-DataFrame-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Setup DataFrame</a></span></li><li><span><a href=\"#Team\" data-toc-modified-id=\"Team-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Team</a></span></li><li><span><a href=\"#Top-6-Club\" data-toc-modified-id=\"Top-6-Club-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Top 6 Club</a></span></li><li><span><a href=\"#Game-Number\" data-toc-modified-id=\"Game-Number-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Game Number</a></span></li><li><span><a href=\"#Team-Points/Scored/Conceded\" data-toc-modified-id=\"Team-Points/Scored/Conceded-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Team Points/Scored/Conceded</a></span></li><li><span><a href=\"#Player-Position\" data-toc-modified-id=\"Player-Position-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Player Position</a></span></li><li><span><a href=\"#Played-Previous-Game\" data-toc-modified-id=\"Played-Previous-Game-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Played Previous Game</a></span></li><li><span><a href=\"#Count-Player's-Games\" data-toc-modified-id=\"Count-Player's-Games-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Count Player's Games</a></span></li><li><span><a href=\"#Value\" data-toc-modified-id=\"Value-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Value</a></span></li><li><span><a href=\"#Team-Total-Points-per-Week\" data-toc-modified-id=\"Team-Total-Points-per-Week-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span>Team Total Points per Week</a></span></li><li><span><a href=\"#Form\" data-toc-modified-id=\"Form-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;</span>Form</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gaussian-Probability-Density-Function\" data-toc-modified-id=\"Gaussian-Probability-Density-Function-3.11.1\"><span class=\"toc-item-num\">3.11.1&nbsp;&nbsp;</span>Gaussian Probability Density Function</a></span></li><li><span><a href=\"#Create-response-function\" data-toc-modified-id=\"Create-response-function-3.11.2\"><span class=\"toc-item-num\">3.11.2&nbsp;&nbsp;</span>Create response function</a></span></li><li><span><a href=\"#Loop-thorugh-players-and-columns-of-interest\" data-toc-modified-id=\"Loop-thorugh-players-and-columns-of-interest-3.11.3\"><span class=\"toc-item-num\">3.11.3&nbsp;&nbsp;</span>Loop thorugh players and columns of interest</a></span></li></ul></li><li><span><a href=\"#Team-Differences\" data-toc-modified-id=\"Team-Differences-3.12\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;</span>Team Differences</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest-Regressor\" data-toc-modified-id=\"Random-Forest-Regressor-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Random Forest Regressor</a></span></li><li><span><a href=\"#Epsilon-Support-Vector-Regression\" data-toc-modified-id=\"Epsilon-Support-Vector-Regression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Epsilon-Support Vector Regression</a></span></li></ul></li><li><span><a href=\"#Visualise-Data\" data-toc-modified-id=\"Visualise-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Visualise Data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Features\n",
    "\n",
    "This script will outline the different processing of developing different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Self explanitory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.278675Z",
     "start_time": "2019-09-28T12:19:41.763836Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "Read player performance, team, fixtures and player data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Player Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.588921Z",
     "start_time": "2019-09-28T12:19:42.280619Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = pd.read_csv('../../data/csv/player_performance.csv')\n",
    "pp = pp.sort_values(by=[\"id\", \"kickoff_time\"]).reset_index(drop=True)\n",
    "pp.head(38)\n",
    "\n",
    "# size of table\n",
    "pp_len = len(pp)\n",
    "\n",
    "# unique player ids\n",
    "player_ids = np.unique(pp[\"id\"])\n",
    "\n",
    "# pre-calculate player id boolean array\n",
    "# each column is a player id, and the rows match those in pp\n",
    "# a value of true means that row belongs to the player whose id is in the column.\n",
    "player_bool = np.zeros((pp_len, len(player_ids)), dtype=\"bool\")\n",
    "for i in player_ids:\n",
    "    player_bool[:, i] = pp[\"id\"] == i\n",
    "player_n_games = np.sum(player_bool, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.607960Z",
     "start_time": "2019-09-28T12:19:42.590521Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "teams = pd.read_csv('../../data/csv/teams.csv')\n",
    "teams.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.621873Z",
     "start_time": "2019-09-28T12:19:42.609440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fixtures = pd.read_csv('../../data/csv/fixtures.csv')\n",
    "fixtures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.634815Z",
     "start_time": "2019-09-28T12:19:42.623640Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "players = pd.read_csv('../../data/csv/players.csv')\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Development\n",
    "\n",
    "Each subsection calculates a different feature. Look under subheading for definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup DataFrame\n",
    "Start by creating a blank DataFrame, and copying only a few key features. This will be the DataFrame that new features get added to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:42.918162Z",
     "start_time": "2019-09-28T12:19:42.899912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "unknown_columns = [\"total_points\", \"minutes\", \"threat\"]\n",
    "known_columns = [\"was_home\", \"opponent_team\"]\n",
    "irrelevant_columns = [\"team\", \"opponent_team\"]\n",
    "\n",
    "columns_to_copy = known_columns + unknown_columns\n",
    "dataset[columns_to_copy] = pp[columns_to_copy]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Team\n",
    "\n",
    "This will add the player's team id as a new column. This needs to be identified through the fixtures DataFrame rather than the players DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.453536Z",
     "start_time": "2019-09-28T12:19:43.038059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Empty array to store team data\n",
    "team = np.zeros(len(pp), dtype=\"int\")\n",
    "\n",
    "# Loop thorugh player performances\n",
    "for i in range(len(pp)):\n",
    "\n",
    "    # extract id of fixture of interest\n",
    "    current_fixture = pp.loc[i, \"fixture\"]\n",
    "\n",
    "    # extract home team id if player was at home, extract away team id if player was away.\n",
    "    if pp.loc[i, \"was_home\"]:\n",
    "        team[i] = fixtures.loc[current_fixture, \"team_h\"]\n",
    "    else:\n",
    "        team[i] = fixtures.loc[current_fixture, \"team_a\"]\n",
    "\n",
    "# Add to dataset\n",
    "dataset[\"team\"] = pd.Series(team)\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 6 Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.470713Z",
     "start_time": "2019-09-28T12:19:43.456910Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"top_6\"] = pd.Series(np.in1d(dataset[\"team\"].values, np.array([0,5,11,12,13,16])))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Number\n",
    "\n",
    "This will put the team's game number into the dataset table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.528595Z",
     "start_time": "2019-09-28T12:19:43.473416Z"
    }
   },
   "outputs": [],
   "source": [
    "game_number = np.zeros((len(fixtures),20), dtype=\"int\")\n",
    "\n",
    "for i in range(0,20):\n",
    "    team_index = np.logical_or(fixtures[\"team_h\"]==i, fixtures[\"team_a\"]==i)\n",
    "    team_df = fixtures.loc[team_index,:].sort_values(by=[\"kickoff_time\"])\n",
    "    #print(team_df.index)\n",
    "    game_number[list(team_df.index),i] = np.array(range(1,39))\n",
    "    \n",
    "irrelevant_columns = irrelevant_columns + [\"team_n_games\", \"opponent_team_n_games\"]\n",
    "dataset[\"team_n_games\"] = pd.Series(game_number[list(pp[\"fixture\"]), list(dataset[\"team\"])])\n",
    "dataset[\"opponent_team_n_games\"] = pd.Series(game_number[list(pp[\"fixture\"]), list(dataset[\"opponent_team\"])])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Points/Scored/Conceded\n",
    "\n",
    "Determine the number of points achieved from the game, and goals scored/conceded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.763388Z",
     "start_time": "2019-09-28T12:19:43.530317Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty array\n",
    "team_points = np.zeros((38, 20), dtype=\"int\")\n",
    "goals_scored = np.zeros((38, 20), dtype=\"int\")\n",
    "goals_conceded = np.zeros((38, 20), dtype=\"int\")\n",
    "\n",
    "for i in range(0, 20):\n",
    "\n",
    "    # extract team info\n",
    "    team_index = np.logical_or(fixtures[\"team_h\"] == i,\n",
    "                               fixtures[\"team_a\"] == i)\n",
    "    team_df = fixtures.loc[team_index, :].sort_values(\n",
    "        by=[\"kickoff_time\"]).reset_index(drop=True)\n",
    "\n",
    "    # determine result\n",
    "    for j in team_df.index:\n",
    "        if (team_df.loc[j, \"team_h_score\"] > team_df.loc[j, \"team_a_score\"]\n",
    "                and team_df.loc[j, \"team_h\"] == i):\n",
    "            team_points[j, i] = 3\n",
    "        elif (team_df.loc[j, \"team_h_score\"] < team_df.loc[j, \"team_a_score\"]\n",
    "              and team_df.loc[j, \"team_a\"] == i):\n",
    "            team_points[j, i] = 3\n",
    "        elif team_df.loc[j, \"team_h_score\"] == team_df.loc[j, \"team_a_score\"]:\n",
    "            team_points[j, i] = 1\n",
    "\n",
    "        # team was home\n",
    "        if team_df.loc[j, \"team_h\"] == i:\n",
    "            goals_scored[j, i] = team_df.loc[j, \"team_h_score\"]\n",
    "            goals_conceded[j, i] = team_df.loc[j, \"team_a_score\"]\n",
    "        else:\n",
    "            goals_scored[j, i] = team_df.loc[j, \"team_a_score\"]\n",
    "            goals_conceded[j, i] = team_df.loc[j, \"team_h_score\"]\n",
    "\n",
    "team_points_prev = np.concatenate((np.zeros(\n",
    "    (1, 20), dtype=\"int\"), team_points[:-1]),\n",
    "                                  axis=0)\n",
    "goals_conceded_prev = np.concatenate((np.zeros(\n",
    "    (1, 20), dtype=\"int\"), goals_conceded[:-1]),\n",
    "                                     axis=0)\n",
    "goals_scored_prev = np.concatenate((np.zeros(\n",
    "    (1, 20), dtype=\"int\"), goals_scored[:-1]),\n",
    "                                   axis=0)\n",
    "\n",
    "team_running_points = np.cumsum(team_points, axis=0)\n",
    "team_running_points_prev = np.concatenate((np.zeros(\n",
    "    (1, 20), dtype=\"int\"), team_running_points[:-1]),\n",
    "                                          axis=0)\n",
    "\n",
    "# team current event\n",
    "dataset[\"team_league_points_won\"] = pd.Series(\n",
    "    team_points[list(dataset[\"team_n_games\"] - 1),\n",
    "                list(dataset[\"team\"])])\n",
    "dataset[\"team_goals_scored\"] = pd.Series(\n",
    "    goals_scored[list(dataset[\"team_n_games\"] - 1),\n",
    "                 list(dataset[\"team\"])])\n",
    "dataset[\"team_goals_conceded\"] = pd.Series(\n",
    "    goals_conceded[list(dataset[\"team_n_games\"] - 1),\n",
    "                   list(dataset[\"team\"])])\n",
    "dataset[\"team_running_league_points_won\"] = pd.Series(\n",
    "    team_running_points[list(dataset[\"team_n_games\"] - 1),\n",
    "                        list(dataset[\"team\"])])\n",
    "\n",
    "# oppoent team current event\n",
    "dataset[\"opponent_team_league_points_won\"] = pd.Series(\n",
    "    team_points[list(dataset[\"team_n_games\"] - 1),\n",
    "                list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_goals_scored\"] = pd.Series(\n",
    "    goals_scored[list(dataset[\"team_n_games\"] - 1),\n",
    "                 list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_goals_conceded\"] = pd.Series(\n",
    "    goals_conceded[list(dataset[\"team_n_games\"] - 1),\n",
    "                   list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_running_league_points_won\"] = pd.Series(\n",
    "    team_running_points[list(dataset[\"team_n_games\"] - 1),\n",
    "                        list(dataset[\"opponent_team\"])])\n",
    "\n",
    "# shift back one\n",
    "dataset[\"team_league_points_won_prev_game\"] = pd.Series(\n",
    "    team_points_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                     list(dataset[\"team\"])])\n",
    "dataset[\"team_goals_scored_prev_game\"] = pd.Series(\n",
    "    goals_scored_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                      list(dataset[\"team\"])])\n",
    "dataset[\"team_goals_conceded_prev_game\"] = pd.Series(\n",
    "    goals_conceded_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                        list(dataset[\"team\"])])\n",
    "dataset[\"team_running_league_points_won_prev_game\"] = pd.Series(\n",
    "    team_running_points_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                             list(dataset[\"team\"])])\n",
    "\n",
    "# opponent\n",
    "dataset[\"opponent_team_league_points_won_prev_game\"] = pd.Series(\n",
    "    team_points_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                     list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_goals_scored_prev_game\"] = pd.Series(\n",
    "    goals_scored_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                      list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_goals_conceded_prev_game\"] = pd.Series(\n",
    "    goals_conceded_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                        list(dataset[\"opponent_team\"])])\n",
    "dataset[\"opponent_team_running_league_points_won_prev_game\"] = pd.Series(\n",
    "    team_running_points_prev[list(dataset[\"team_n_games\"] - 1),\n",
    "                             list(dataset[\"opponent_team\"])])\n",
    "\n",
    "dataset[\"team_running_points_difference\"] = dataset[\n",
    "    \"team_running_league_points_won_prev_game\"] - dataset[\n",
    "        \"opponent_team_running_league_points_won_prev_game\"]\n",
    "\n",
    "dataset[\"team_running_points_difference_bool\"] = dataset[\"team_running_points_difference\"]>15\n",
    "\n",
    "unknown_columns = unknown_columns + [\n",
    "    \"team_league_points_won\", \"team_goals_scored\", \"team_goals_conceded\",\n",
    "    \"team_running_league_points_won\",\n",
    "    \"opponent_team_league_points_won\", \"opponent_team_goals_scored\",\n",
    "    \"opponent_team_goals_conceded\", \"opponent_team_running_league_points_won\"\n",
    "]\n",
    "\n",
    "dataset.head(38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Player Position\n",
    "\n",
    "This will add a column filled with values 0, 1, 2 and 3. Each describes a different position. This will then be converted using One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.778370Z",
     "start_time": "2019-09-28T12:19:43.765989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add position category value\n",
    "dataset[\"position\"] = players.loc[np.array(pp[\"id\"]), \"position\"].reset_index(\n",
    "    drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.787389Z",
     "start_time": "2019-09-28T12:19:43.779898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "onehotencoder = sklearn.preprocessing.OneHotEncoder(sparse=False,\n",
    "                                                    categories=\"auto\")\n",
    "position_ohe = onehotencoder.fit_transform(dataset[\"position\"].values.reshape(\n",
    "    len(pp), 1))\n",
    "dataset[[\"GKP\", \"DEF\", \"MID\", \"FWD\"]] = pd.DataFrame(position_ohe == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:43.813002Z",
     "start_time": "2019-09-28T12:19:43.789007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop position ordinal value\n",
    "dataset = dataset.drop(columns=[\"position\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Played Previous Game\n",
    "\n",
    "This will return a boolean array which indicates if the player featured in the previous game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:44.029476Z",
     "start_time": "2019-09-28T12:19:43.814939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shiftBool(xs, n):\n",
    "    if n >= 0:\n",
    "        return np.concatenate((np.full(n, False), xs[:-n]))\n",
    "    else:\n",
    "        return np.concatenate((xs[-n:], np.full(-n, False)))\n",
    "\n",
    "# empty boolean array\n",
    "played_last_game = np.zeros(pp_len, dtype=\"bool\")\n",
    "\n",
    "# loop through players\n",
    "for i in player_ids:\n",
    "    \n",
    "    player_col = pp.loc[player_bool[:, i], \"minutes\"]\n",
    "    player_index = player_col.index\n",
    "    player_values = player_col.values\n",
    "    player_values_bool  = player_values>0\n",
    "    player_values_shifted = shiftBool(player_values_bool,1)\n",
    "    played_last_game[list(player_index)] = player_values_shifted\n",
    "    \n",
    "dataset[\"played_last_game\"] = pd.Series(played_last_game)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Count Player's Games\n",
    "\n",
    "This will keep a running tally of the number of games a player has been in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:44.266623Z",
     "start_time": "2019-09-28T12:19:44.031271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# empty array\n",
    "nGames = np.zeros(pp_len, dtype=\"int\")\n",
    "\n",
    "# loop thorugh players\n",
    "for i in player_ids:\n",
    "    \n",
    "    player_col = pp.loc[player_bool[:, i], \"was_home\"]\n",
    "    player_index = player_col.index\n",
    "    nGames[list(player_index)] = np.array(range(len(player_index)))\n",
    "    \n",
    "irrelevant_columns = irrelevant_columns + [\"player_n_games\"]\n",
    "dataset[\"player_n_games\"] = pd.Series(nGames)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value\n",
    "\n",
    "This will grab the value of the player from the previous week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:44.533359Z",
     "start_time": "2019-09-28T12:19:44.269212Z"
    }
   },
   "outputs": [],
   "source": [
    "def shiftFloat(xs, n):\n",
    "    if n >= 0:\n",
    "        return np.concatenate((np.full(n, 0), xs[:-n]))\n",
    "    else:\n",
    "        return np.concatenate((xs[-n:], np.full(-n, 0)))\n",
    "\n",
    "# empty boolean array\n",
    "prev_value = np.zeros(pp_len, dtype=\"float\")\n",
    "diff_value = np.zeros(pp_len, dtype=\"float\")\n",
    "\n",
    "# loop through players\n",
    "for i in player_ids:\n",
    "    \n",
    "    player_col = pp.loc[player_bool[:, i], \"value\"]\n",
    "    player_index = player_col.index\n",
    "    player_values = player_col.values\n",
    "    player_values_shifted = shiftFloat(player_values,1)\n",
    "    prev_value[list(player_index)] = player_values_shifted\n",
    "    diff_value[list(player_index)] = player_values_shifted-player_values[0]\n",
    "    \n",
    "    \n",
    "dataset[\"prev_value\"] = pd.Series(prev_value)\n",
    "dataset[\"value_diff\"] = pd.Series(diff_value)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Total Points per Week\n",
    "\n",
    "Calculate the total number of FPL points a team got each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:45.884529Z",
     "start_time": "2019-09-28T12:19:44.535120Z"
    }
   },
   "outputs": [],
   "source": [
    "team_total_points = np.zeros((38,20), dtype=\"int\")\n",
    "\n",
    "# loop thorugh teams\n",
    "for i in range(0,20):\n",
    "    for j in range(0,38):\n",
    "        team_df = dataset[dataset[\"team\"]==i]\n",
    "        team_gameweek_df = team_df[(team_df[\"team_n_games\"]-1)==j]\n",
    "        team_total_points[j,i] = np.sum(team_gameweek_df[\"total_points\"])\n",
    "        \n",
    "dataset[\"team_total_points\"] = pd.Series(team_total_points[list(dataset[\"team_n_games\"]-1), list(dataset[\"team\"])])\n",
    "dataset[\"player_point_contribution\"] = 100*dataset[\"total_points\"]/dataset[\"team_total_points\"]\n",
    "unknown_columns = unknown_columns + [\"team_total_points\", \"player_point_contribution\"]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form\n",
    "\n",
    "Calculates weighted average from previous games. More recent games have a higher weighting. This is performed using convolution between the column of interest and a response function which only takes into account previous games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Probability Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:45.893497Z",
     "start_time": "2019-09-28T12:19:45.888308Z"
    }
   },
   "outputs": [],
   "source": [
    "# normpdf function\n",
    "import math\n",
    "def normpdf(x, mu, sigma):\n",
    "    if np.isinf(sigma):\n",
    "        return np.ones(len(x), dtype=\"float\")*(1/len(x))\n",
    "    else:\n",
    "        return (1/np.sqrt(2*math.pi*(sigma**2)))*np.exp(-((x-mu)**2)/(2*(sigma**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create response function\n",
    "\n",
    "Th number of games to consider can be directly defined and the relative weighting is defined using the standard deviation. Using a standard deviation of $\\infty$ will give all games equal weightings. This will be used in a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:46.138806Z",
     "start_time": "2019-09-28T12:20:46.016613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Response Function for c\n",
    "nPreviousGames = 2\n",
    "sigma = np.inf\n",
    "# sigma = infinty mean all games have an equal weighting\n",
    "\n",
    "response = np.zeros((2*nPreviousGames)+1, dtype=\"float\")\n",
    "response[(nPreviousGames+1):] = normpdf(np.array(range(nPreviousGames)), 0, sigma)\n",
    "response = response/np.sum(response)\n",
    "\n",
    "plt.plot(response);\n",
    "plt.ylabel('relative weighting');\n",
    "plt.xlabel('n games into the past');\n",
    "plt.xticks(np.array(range(nPreviousGames,(2*nPreviousGames)+1)), labels=list(range(nPreviousGames+1)));\n",
    "plt.title('Convolution kernel for moving weighted average on previous games');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:19:46.138280Z",
     "start_time": "2019-09-28T12:19:46.127535Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop thorugh players and columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:21:05.601672Z",
     "start_time": "2019-09-28T12:20:49.619009Z"
    }
   },
   "outputs": [],
   "source": [
    "# requires the convolve function from scipy package\n",
    "# numpy has a convolve function also, but the output doesn't match the input size.\n",
    "from scipy.signal import convolve\n",
    "\n",
    "# calculate the form on these columns\n",
    "form_on_columns = [\n",
    "    \"total_points\", \"minutes\", \"threat\", \"team_league_points_won\",\n",
    "    \"team_goals_scored\", \"team_goals_conceded\", \"team_total_points\", \"player_point_contribution\",\n",
    "    \"opponent_team_league_points_won\", \"opponent_team_goals_scored\", \"opponent_team_goals_conceded\"\n",
    "]\n",
    "\n",
    "# length of pp dataframe\n",
    "pp_len = len(pp)\n",
    "\n",
    "# loop thorugh columns\n",
    "for i in form_on_columns:\n",
    "\n",
    "    # nan array for\n",
    "    overall_form = np.zeros(pp_len, dtype=\"float\")\n",
    "    home_form = np.zeros(pp_len, dtype=\"float\")\n",
    "    away_form = np.zeros(pp_len, dtype=\"float\")\n",
    "\n",
    "    # loop through players\n",
    "    for j in player_ids:\n",
    "\n",
    "        # overall form\n",
    "        player_col = dataset.loc[player_bool[:, j], [\"was_home\", i]]\n",
    "        player_index = player_col.index\n",
    "        player_values = player_col[i].values\n",
    "        player_form = convolve(player_values, response, mode=\"same\")\n",
    "        overall_form[list(player_index)] = player_form\n",
    "\n",
    "        # home form\n",
    "        player_home_col = player_col.loc[player_col[\"was_home\"], :]\n",
    "        if len(player_home_col) > 0:\n",
    "            player_home_index = player_home_col.index\n",
    "            player_home_values = player_home_col[i].values\n",
    "            player_home_form = convolve(player_home_values,\n",
    "                                        response,\n",
    "                                        mode=\"same\")\n",
    "            home_form[list(player_home_index)] = player_home_form\n",
    "\n",
    "        # away form\n",
    "        player_away_col = player_col.loc[~player_col[\"was_home\"], :]\n",
    "        if len(player_away_col) > 0:\n",
    "            player_away_index = player_away_col.index\n",
    "            player_away_values = player_away_col[i].values\n",
    "            player_away_form = convolve(player_away_values,\n",
    "                                        response,\n",
    "                                        mode=\"same\")\n",
    "            away_form[list(player_away_index)] = player_away_form\n",
    "\n",
    "    # add to dataset\n",
    "    dataset[i + \"_overall_form\"] = pd.Series(overall_form)\n",
    "    #dataset[i + \"_home_form\"] = pd.Series(home_form)\n",
    "    #dataset[i + \"_away_form\"] = pd.Series(away_form)\n",
    "    dataset[i + \"_relevant_form\"] = pd.Series(home_form + away_form)\n",
    "\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Team Differences\n",
    "\n",
    "This will calculate differences between the player's team and their oppoisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:21:11.066923Z",
     "start_time": "2019-09-28T12:21:11.061452Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset[\"league_points_form_difference\"] = dataset[\"team_league_points_won_overall_form\"] - dataset[\"opponent_team_league_points_won_overall_form\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:21:15.036610Z",
     "start_time": "2019-09-28T12:21:14.951918Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate labels and features\n",
    "dataset_filter = dataset.copy()\n",
    "dataset_filter = dataset_filter[dataset_filter[\"player_n_games\"] >= nPreviousGames]\n",
    "\n",
    "# Get labels\n",
    "dataset_labels = dataset_filter[\"total_points\"]\n",
    "\n",
    "# separated features and labels\n",
    "remove_columns = unknown_columns + irrelevant_columns\n",
    "dataset_features = dataset_filter.drop(columns=remove_columns)\n",
    "\n",
    "# drop relevant form columns\n",
    "#dataset_features = dataset_features[dataset_features.columns.drop(list(dataset_features.filter(regex='relevant')))]\n",
    "\n",
    "# drop overall form\n",
    "#dataset_features = dataset_features[dataset_features.columns.drop(list(dataset_features.filter(regex='overall')))]\n",
    "\n",
    "# drop prevgame\n",
    "dataset_features = dataset_features[dataset_features.columns.drop(list(dataset_features.filter(regex='prev_game')))]\n",
    "\n",
    "dataset_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:03.326381Z",
     "start_time": "2019-09-28T12:20:03.313827Z"
    }
   },
   "outputs": [],
   "source": [
    "# # import models\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# # convert to array\n",
    "# features = dataset_features.values\n",
    "# labels = dataset_labels.values\n",
    "\n",
    "# # train-test split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(features,\n",
    "#                                                     labels,\n",
    "#                                                     test_size=0.2,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "# # establish baseline\n",
    "# baseline_error = np.mean(np.abs(Y_train - np.median(Y_train)))\n",
    "# print(\"average regressor - training mean absolute difference: \" +\n",
    "#       str(baseline_error))\n",
    "\n",
    "# # train random forest\n",
    "# rf = RandomForestRegressor(n_estimators=1000, random_state=42, max_depth=5)\n",
    "# rf.fit(X_train, Y_train)\n",
    "\n",
    "# train_predictions = rf.predict(X_train)\n",
    "# rf_train_error = np.mean(np.abs(Y_train - train_predictions))\n",
    "# print(\"random forest regressor - training mean absolute difference: \" +\n",
    "#       str(rf_train_error))\n",
    "\n",
    "# test_predictions = rf.predict(X_test)\n",
    "# rf_test_error = np.mean(np.abs(Y_test - test_predictions))\n",
    "# print(\"random forest regressor - test mean absolute difference: \" +\n",
    "#       str(rf_test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:03.331351Z",
     "start_time": "2019-09-28T12:20:03.328339Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_investigate = dataset_features.copy()\n",
    "# dataset_investigate[\"total_points\"] = dataset[\"total_points\"]\n",
    "# dataset_investigate[\"total_points_predictions\"] = pd.Series(test_predictions)\n",
    "# dataset_investigate.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:03.335335Z",
     "start_time": "2019-09-28T12:20:03.332707Z"
    }
   },
   "outputs": [],
   "source": [
    "# importances = rf.feature_importances_\n",
    "# plt.figure(figsize=(16,10))\n",
    "# cols = list(dataset_features.columns);\n",
    "# plt.bar(cols, importances)\n",
    "# plt.xticks(rotation=\"vertical\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:03.339336Z",
     "start_time": "2019-09-28T12:20:03.336758Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_investigate[\"diff\"] = np.abs(dataset_investigate[\"total_points\"]-dataset_investigate[\"total_points_predictions\"])\n",
    "# dataset_investigate = dataset_investigate.sort_values(by=[\"diff\"], ascending =True)\n",
    "# dataset_investigate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon-Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:21:36.721527Z",
     "start_time": "2019-09-28T12:21:17.034682Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# convert to array\n",
    "features = dataset_features.values\n",
    "labels = dataset_labels.values\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "features = scaler.fit_transform(dataset_features.values)\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "clf = SVR(gamma='scale', C=1, epsilon=0.01)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# establish baseline\n",
    "baseline_error = np.mean(np.abs(Y_train - np.median(Y_train)))\n",
    "print(\"median regressor - training mean absolute difference: \" +\n",
    "      str(baseline_error))\n",
    "\n",
    "clf_train_predictions = clf.predict(X_train)\n",
    "clf_train_error = np.mean(np.abs(Y_train - clf_train_predictions))\n",
    "print(\"SVM regressor - training mean absolute difference: \" +\n",
    "      str(clf_train_error))\n",
    "\n",
    "clf_test_predictions = clf.predict(X_test)\n",
    "clf_test_error = np.mean(np.abs(Y_test - clf_test_predictions))\n",
    "print(\"SVM regressor - test mean absolute difference: \" +\n",
    "      str(clf_test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:24.263034Z",
     "start_time": "2019-09-28T12:20:24.211683Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_investigate = dataset_features.copy()\n",
    "dataset_investigate[\"total_points\"] = dataset[\"total_points\"]\n",
    "dataset_investigate[\"total_points_predictions\"] = pd.Series(clf_test_predictions)\n",
    "dataset_investigate = dataset_investigate.sort_values(by=[\"total_points_predictions\"], ascending=False)\n",
    "dataset_investigate.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:20:24.592511Z",
     "start_time": "2019-09-28T12:20:24.264720Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind=\"scatter\",\n",
    "             x=\"minutes_overall_form\",\n",
    "             y=\"total_points\",\n",
    "             alpha=0.5,\n",
    "            figsize=(10,7))\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:33:52.963131Z",
     "start_time": "2019-09-28T12:33:52.952987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5443952f5b474a4b903c64748c3c0790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Grid', icon='check')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_button = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Grid',\n",
    "    icon='check'\n",
    ")\n",
    "grid_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T12:34:00.894044Z",
     "start_time": "2019-09-28T12:34:00.891014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(grid_button.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
